---
services:

  clickhouse:
    image: clickhouse/clickhouse-server:25.8.13
    container_name: clickhouse
    hostname: clickhouse
    user: "101:101"
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - "clickhouse_logs:/var/log/clickhouse-server"
      - "clickhouse_data:/var/lib/clickhouse"
      - "./clickhouse/init:/docker-entrypoint-initdb.d"
    environment:
      - CLICKHOUSE_DB=vector
      - CLICKHOUSE_USER=vector
      - CLICKHOUSE_PASSWORD=vector
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:8123/ping"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs

  elasticsearch:
    image: elasticsearch:9.2.3
    container_name: elasticsearch
    hostname: elasticsearch
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
    volumes:
      - "elasticsearch_data:/usr/share/elasticsearch/data"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs

  zookeeper:
    container_name: zookeeper
    hostname: zookeeper
    image: confluentinc/cp-zookeeper:7.5.0
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_4LW_COMMANDS_WHITELIST: "stat,ruok,srvr,conf"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - logs

  kafka:
    container_name: kafka
    hostname: kafka
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 15s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - logs
    depends_on:
      zookeeper:
        condition: service_healthy

  kafka-ui:
    container_name: kafka-ui
    hostname: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: "local-cluster"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9092"
      KAFKA_CLUSTERS_0_ZOOKEEPER: "zookeeper:2181"
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: "PLAINTEXT"
      KAFKA_CLUSTERS_0_READONLY: "false"
      DYNAMIC_CONFIG_ENABLED: "true"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/actuator/health"]
      interval: 20s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - logs
    depends_on:
      kafka:
        condition: service_healthy

  kibana:
    image: kibana:9.2.3
    container_name: kibana
    hostname: kibana
    ports:
      - 5601:5601
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs
    depends_on:
      elasticsearch:
        condition: service_healthy
  
  vector-kafka:
    image: timberio/vector:0.52.0-alpine
    container_name: vector-kafka
    hostname: vector-kafka
    ports:
      - "8383:8383"
      - "8686:8686"
    volumes:
      - "./nginx/logs:/var/log/nginx:ro"
      - "./vector/vector-kafka.yaml:/etc/vector/vector.yaml:ro"
    environment:
      - VECTOR_LOG=info
    healthcheck:
      test: ["CMD", "vector", "validate", "/etc/vector/vector.yaml"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs
    depends_on:
      clickhouse:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kafka:
        condition: service_healthy

  vector-database:
    image: timberio/vector:0.52.0-alpine
    container_name: vector-database
    hostname: vector-database
    # ports:
    #   - "8383:8383"
    #   - "8686:8686"
    volumes:
      - "./vector/vector-database.yaml:/etc/vector/vector.yaml:ro"
    environment:
      - VECTOR_LOG=info
    healthcheck:
      test: ["CMD", "vector", "validate", "/etc/vector/vector.yaml"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs
    depends_on:
      clickhouse:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kafka:
        condition: service_healthy

  nginx:
    container_name: nginx
    hostname: nginx
    build:
      context: ./nginx
    restart: always
    ports:
      - "80:80"
    volumes:
      - "./nginx/logs/:/var/log/nginx"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:80"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs
    depends_on:
      clickhouse:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      vector-database:
        condition: service_healthy
      vector-kafka:
        condition: service_healthy

  grafana:
    image: grafana/grafana:12.4.0-20648027705-ubuntu
    container_name: grafana
    hostname: grafana
    volumes:
      - "./grafana/datasources.yaml:/etc/grafana/provisioning/datasources/datasources.yaml"
      - "./grafana/dashboards.yaml:/etc/grafana/provisioning/dashboards/dashboards.yaml"
      - "./grafana/vector.json:/var/lib/grafana/dashboards/vector.json"
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ALLOW_EMBEDDING=true
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_INSTALL_PLUGINS=grafana-clickhouse-datasource
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 10s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - logs
    depends_on:
      clickhouse:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy

  alpine:
    image: alpine:latest
    container_name: alpine
    hostname: alpine
    command: 
      - /bin/sh
      - -c
      - |
        apk add curl
        while true; 
        do sleep 1; 
        curl http://www.google.com;
        done
    networks:
      - logs

networks:
  logs:
    driver: bridge

volumes:
  clickhouse_data:
    driver: local
  clickhouse_logs:
    driver: local
  elasticsearch_data:
    driver: local
